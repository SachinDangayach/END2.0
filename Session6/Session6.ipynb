{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_6TKwDda4I2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchtext.legacy\n",
        "from torchtext import datasets\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import re\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "import spacy\n",
        "import nltk\n",
        "# from nltk.corpus import stopwords, wordnet\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "import random\n",
        "import os, pickle\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import  accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W61b3a_C3X4q"
      },
      "source": [
        "## Load Tweets Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_h-bSX5bl72"
      },
      "source": [
        "tweets = pd.read_csv('/content/session6/tweets.csv', encoding = 'latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "p9NKyAkH30bm",
        "outputId": "284f9f4e-e129-4674-ab12-5e82f46593e6"
      },
      "source": [
        "tweets.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Obama has called the GOP budget social Darwini...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In his teen years, Obama has been known to use...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IPA Congratulates President Barack Obama for L...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RT @Professor_Why: #WhatsRomneyHiding - his co...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>RT @wardollarshome: Obama has approved more ta...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tweets  labels\n",
              "0  Obama has called the GOP budget social Darwini...       1\n",
              "1  In his teen years, Obama has been known to use...       0\n",
              "2  IPA Congratulates President Barack Obama for L...       0\n",
              "3  RT @Professor_Why: #WhatsRomneyHiding - his co...       0\n",
              "4  RT @wardollarshome: Obama has approved more ta...       1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7YaRkEy37nE",
        "outputId": "104582a0-85de-4fa4-da09-a90ec1d6a850"
      },
      "source": [
        "tweets.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    931\n",
              "1    352\n",
              "2     81\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "z-emPO3V4FXp",
        "outputId": "119c4f95-6e67-41c7-ebdd-c77a65cc6bae"
      },
      "source": [
        "fig = plt.figure(figsize=(8,6))\n",
        "\n",
        "ax = sns.barplot(x=tweets['labels'].unique(), y=tweets['labels'].value_counts())\n",
        "\n",
        "ax.set(xlabel = 'Labels')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0.5, 0, 'Labels')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZMo9Tak4rnQ"
      },
      "source": [
        "### Data is imbalanced and should be made balanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEh_lIaj5S5V"
      },
      "source": [
        "## Data cleanup, Train Test Split and prepare Vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4rhlk4V4Z5a"
      },
      "source": [
        "train, test = train_test_split(tweets, test_size= .2, random_state= 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9kXuqgc5_h1",
        "outputId": "a3124451-2933-4808-f8b7-6af0ea8232b7"
      },
      "source": [
        "train.reset_index(drop=True), test.reset_index(drop=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                                 tweets  labels\n",
              " 0     I'm Michelle Obama, u Kim K, C'mon bitch u see...       0\n",
              " 1     LOOOOOOOOOOOOOOOOOOOOOOOOOOOOL This is why i r...       0\n",
              " 2     RT @WhatTheFFacts: In his teen years, Obama ha...       0\n",
              " 3     President Obama * Lindsay Lohan RUMORS video s...       0\n",
              " 4     Barack Obama LONGBOARD Package CORE 7\" TRUCKS ...       0\n",
              " ...                                                 ...     ...\n",
              " 1086  #WhatsRomneyHiding Obama released his tax retu...       0\n",
              " 1087                #KimKardashiansNextBoyFriend Obama!       0\n",
              " 1088  RT @larryeldershow: Spike Lee said he dislikes...       0\n",
              " 1089  RT @pourmecoffee: White House Easter Egg Roll ...       1\n",
              " 1090  #WhatsRomneyHiding His relationship with Vera ...       0\n",
              " \n",
              " [1091 rows x 2 columns],\n",
              "                                                 tweets  labels\n",
              " 0    RT @ohgirlphrase: American kid \"You're from th...       0\n",
              " 1    Examiner Editorial: Obama's budget, not Ryan's...       0\n",
              " 2    Obama on Constitutional Law: Did He Lie or Is ...       0\n",
              " 3    Amid Trayvon Martin case, Obama hosts screenin...       0\n",
              " 4    @geoff9cow Right! Of course! It's ALWAYS someo...       1\n",
              " ..                                                 ...     ...\n",
              " 268  RT @nprnews: Obama's Signing Of JOBS Act Likel...       0\n",
              " 269  RT @GarrettNBCNews: Romney, who earned a combi...       1\n",
              " 270  Exposing the Obama-Soetoro deception: http://t...       0\n",
              " 271  #newbedon 4/6/2012 4:25:20 AM Obama Wins Lands...       0\n",
              " 272  Obama Concedes That Courts Can Review Acts of ...       0\n",
              " \n",
              " [273 rows x 2 columns])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5rd2SCA6DEQ"
      },
      "source": [
        "def tweet_clean(text):\n",
        "  text = re.sub(r'[^A-Za-z0-9_-]+', ' ', text)\n",
        "  text = re.sub(r'https?:/\\/\\S+', ' ', text)\n",
        "\n",
        "  return(text.strip())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B229e9kg6Phg"
      },
      "source": [
        "nlp = spacy.load('en', disable = ['parser', 'tagger', 'ner'])\n",
        "def tokenizer(s):\n",
        "  return [w.text.lower() for w in nlp(tweet_clean(s))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTH0Kpyr6QTK"
      },
      "source": [
        "TEXT = torchtext.legacy.data.Field(tokenize=tokenizer, lower=True, init_token= '<sos>', eos_token= '<eos>')\n",
        "\n",
        "LABEL = torchtext.legacy.data.LabelField(tokenize = tokenizer)\n",
        "\n",
        "# english = torchtext.legacy.data.Field(tokenize=tokenizer_end, lower=True, init_token= '<sos>', eos_token= '<eos>')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8no00lr7ob7"
      },
      "source": [
        "datafields = [('tweets', TEXT), ('labels', LABEL)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFIqIxNm9UT1"
      },
      "source": [
        "### Split and save datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-q23JJQ49aFy"
      },
      "source": [
        "train.to_csv('session6/train.csv', index=False)\n",
        "test.to_csv('session6/test.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXBOBV9W8agI"
      },
      "source": [
        "trn, tst = torchtext.legacy.data.TabularDataset.splits(path='/content/session6',\n",
        "                                                       train = 'train.csv',\n",
        "                                                       test = 'test.csv',\n",
        "                                                       format = 'csv',\n",
        "                                                       skip_header = True,\n",
        "                                                       fields = datafields\n",
        "                                                       )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UfOlwAC8wrk",
        "outputId": "4716373d-9f23-4c7a-acfc-2eed8d3aaa7f"
      },
      "source": [
        "print(f'Number of training examples: {len(trn)}')\n",
        "print(f'Number of testing examples: {len(tst)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training examples: 1091\n",
            "Number of testing examples: 273\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmrPFX1T8x16",
        "outputId": "941bbeee-5d86-4d4d-a689-8e80c6b34a74"
      },
      "source": [
        "vars(trn.examples[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': '0',\n",
              " 'tweets': ['i',\n",
              "  'm',\n",
              "  'michelle',\n",
              "  'obama',\n",
              "  'u',\n",
              "  'kim',\n",
              "  'k',\n",
              "  'c',\n",
              "  'mon',\n",
              "  'bitch',\n",
              "  'u',\n",
              "  'see',\n",
              "  'where',\n",
              "  'the',\n",
              "  'black',\n",
              "  'president',\n",
              "  'at']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXNLd8gA-gjH"
      },
      "source": [
        "TEXT.build_vocab(trn, max_size = 10000,\n",
        "                #  vectors = \"glove.6B.100d\",\n",
        "                min_freq = 2 \n",
        "                )\n",
        "\n",
        "LABEL.build_vocab(trn) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ2QVJDc_Mfn",
        "outputId": "8363e00d-a12b-4165-d8a2-8ab6fa20f912"
      },
      "source": [
        "print(TEXT.vocab.freqs.most_common(50))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('obama', 1095), ('the', 552), ('rt', 496), ('t', 455), ('to', 394), ('co', 390), ('http', 388), ('s', 309), ('you', 285), ('a', 250), ('of', 234), ('is', 230), ('with', 205), ('in', 201), ('-', 181), ('do', 178), ('on', 165), ('and', 164), ('that', 164), ('i', 160), ('he', 157), ('kid', 145), ('for', 139), ('whatsromneyhiding', 135), ('his', 129), ('so', 126), ('like', 125), ('from', 117), ('president', 102), ('romney', 100), ('have', 99), ('it', 94), ('go', 91), ('not', 86), ('re', 85), ('at', 82), ('american', 79), ('cool', 77), ('has', 76), ('can', 75), ('uk', 72), ('ohhh', 72), ('tea', 72), ('queen', 72), ('british', 72), ('mcdonalds', 72), ('gop', 70), ('we', 69), ('ohgirlphrase', 68), ('tcot', 67)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRLpAAJs_PJ9",
        "outputId": "8491df7b-f533-4d07-f842-8c7d209391eb"
      },
      "source": [
        "print(TEXT.vocab.itos[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['<unk>', '<pad>', '<sos>', '<eos>', 'obama', 'the', 'rt', 't', 'to', 'co']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7zPd8IR_zSt",
        "outputId": "74e44ed5-8610-4720-d9d1-8e3a28898c3c"
      },
      "source": [
        "print(LABEL.vocab.itos)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['0', '1', '2']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCXADYJj_Y0p",
        "outputId": "71cdc929-fa06-4489-e32b-567626ea09ad"
      },
      "source": [
        "print(LABEL.vocab.stoi)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {'0': 0, '1': 1, '2': 2})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Othsv5nI_5Wz"
      },
      "source": [
        "## Build Model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M68tAxxo_ck7"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size):\n",
        "    super(Encoder, self).__init__()\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size)\n",
        "    self.rnn = nn.LSTM(embedding_size, hidden_size)\n",
        "    # self.dropout = nn.Dropout(p_do)\n",
        "\n",
        "  def forward(self,x):\n",
        "    # x shape: (seq_length, N)\n",
        "    embedding = self.embedding(x)\n",
        "\n",
        "    # embedding shape: (seq_length, N, embedding_size)\n",
        "    output, (hidden, cell) = self.rnn(embedding)\n",
        "\n",
        "    print(f'encoder {output.shape}, {hidden.shape}, {cell.shape}')\n",
        "    # output = \n",
        "    return output, hidden, cell\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, c_state_size, output_size):\n",
        "      super(Decoder, self).__init__()\n",
        "\n",
        "      self.rnn = nn.LSTM(input_size, hidden_size)\n",
        "      self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden, cell):\n",
        "      # shape of x: (N) but we want (1,N)\n",
        "      x = x.unsqueeze(0) \n",
        "\n",
        "      # embedding = self.dropout(self.embedding(x))\n",
        "      # embedding shape will be (1, N, embedding_size)\n",
        "\n",
        "\n",
        "      print(f'decoder {x.shape}, {hidden.shape}, {cell.shape}')\n",
        "      outputs, (hidden, cell) = self.rnn(x.squeeze(0),(hidden, cell)) \n",
        "      print(f'decder output,hidden and cell shape {outputs.shape}, {hidden.shape}, {cell.shape}')\n",
        "\n",
        "      # shape of outputs: (1, N, hidden_size)\n",
        "\n",
        "      predictions = self.fc(outputs)\n",
        "      print(f'prediction in decoder: {predictions.shape}')\n",
        "      # shape of predictoin: (1,N, length_of_vocab)\n",
        "\n",
        "      # predictions = predictions.squeeze(0)\n",
        "\n",
        "      return predictions, hidden, cell\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):\n",
        "  def __init__(self, encoder, decoder):\n",
        "    super(Seq2Seq, self).__init__()\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "\n",
        "  def forward(self, source, target):\n",
        "    print(f'seq 2 seq {source.shape} target {target.shape}')\n",
        "    batch_size = source.shape[1]    # (source_len, N)\n",
        "    target_len = target.shape[0]    # (target_len)\n",
        "    target_vocab_size = len(LABEL.vocab)\n",
        "\n",
        "    # outputs = torch.zeros(target_len, batch_size, target_vocab_size).to(device)\n",
        "\n",
        "    op, hidden, cell = self.encoder(source)\n",
        "\n",
        "    # Grab start token\n",
        "    x = op\n",
        "\n",
        "    predictions, d_hidden, d_cell = self.decoder(x, hidden, cell)\n",
        "\n",
        "    predictions = predictions[]\n",
        "    print(predictions.shape)\n",
        "    best_pred= predictions.argmax()\n",
        "\n",
        "    return best_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QasO1sz4f9-O"
      },
      "source": [
        "### Initialize Training Parameters\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoWiMY3LXw0G"
      },
      "source": [
        "## Training starts -\n",
        "\n",
        "# Training hyperparameters\n",
        "num_epochs = 1\n",
        "learning_rate = 0.001\n",
        "batch_size = 8\n",
        "\n",
        "# Model hyperparameters\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "input_size_encoder = len(TEXT.vocab)\n",
        "input_size_decoder = 256 # Hidden dimention for output\n",
        "output_size = len(LABEL.vocab)\n",
        "encoder_embedding_size = 100\n",
        "\n",
        "cell_state_size = 256\n",
        "hidden_size = 256\n",
        "num_layers = 1\n",
        "\n",
        "# # Tensorboard\n",
        "# writer = SummaryWriter(f'runs/loss_plot')\n",
        "# step = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TERDOcWqgFlF"
      },
      "source": [
        "## Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxlMR1JsgEyU"
      },
      "source": [
        "# Get iterators\n",
        "train_iterator, test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
        "    (trn, tst),\n",
        "    batch_size = batch_size,\n",
        "    sort_within_batch = True,\n",
        "    sort_key = lambda x: len(x.tweets),\n",
        "    device= device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jU1B0HlfgleZ"
      },
      "source": [
        "## Initialize Models, Optimizer and define Criterion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I2Y7MRSeZmp"
      },
      "source": [
        "encoder_net = Encoder(input_size_encoder, encoder_embedding_size, \n",
        "                      hidden_size).to(device)\n",
        "\n",
        "decoder_net = Decoder(input_size_decoder, hidden_size, cell_state_size, output_size).to(device)\n",
        "\n",
        "model = Seq2Seq(encoder_net, decoder_net).to(device)\n",
        "\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
        "\n",
        "pad_idx = TEXT.vocab.stoi['<pad>']\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "skgZScFTeaYY",
        "outputId": "bb3d2b40-9461-4ead-d378-15636e1cb494"
      },
      "source": [
        "for epoch in range(num_epochs):\n",
        "  print(f'Epoch [{epoch} / {num_epochs}]')\n",
        "\n",
        "  for batch_idx, batch in enumerate(train_iterator):\n",
        "    inp_data = batch.tweets.to(device)\n",
        "    target = batch.labels.to(device)\n",
        "\n",
        "    output = model(inp_data, target)\n",
        "    # output shape: target_len, batch_size, output_dim\n",
        "    print(f\"output {output}, target {target}\")\n",
        "    # output = output[1:].reshape(-1, output.shape[2])\n",
        "    # target = target[1:].reshape(-1)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss = criterion(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "    optimizer.step()\n",
        "\n",
        "    writer.add_scalar('Training Loss', loss, global_step=step)\n",
        "    step += 1\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0 / 1]\n",
            "seq 2 seq torch.Size([23, 8]) target torch.Size([8])\n",
            "encoder torch.Size([23, 8, 256]), torch.Size([1, 8, 256]), torch.Size([1, 8, 256])\n",
            "decoder torch.Size([1, 23, 8, 256]), torch.Size([1, 8, 256]), torch.Size([1, 8, 256])\n",
            "decder output,hidden and cell shape torch.Size([23, 8, 256]), torch.Size([1, 8, 256]), torch.Size([1, 8, 256])\n",
            "prediction in decoder: torch.Size([23, 8, 3])\n",
            "torch.Size([23, 8, 3])\n",
            "output 71, target tensor([0, 0, 1, 1, 0, 0, 0, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-3eaf062a8a60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m-> 1048\u001b[0;31m                                ignore_index=self.ignore_index, reduction=self.reduction)\n\u001b[0m\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   1670\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"log_softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1672\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1673\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qARgmxXg1D7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c8a24d2-fb4a-4594-defb-cb78032ada78"
      },
      "source": [
        "m = nn.Linear(256, 3)\n",
        "input = torch.randn(23, 8, 256)\n",
        "output = m(input)\n",
        "print(output.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([23, 8, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Bfpow-32d85"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}